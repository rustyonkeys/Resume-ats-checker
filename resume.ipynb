{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6a86a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\shreyas\\appdata\\roaming\\python\\python38\\site-packages (0.11.5)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atchdog (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -equests (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pytesseract in c:\\users\\shreyas\\appdata\\roaming\\python\\python38\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\shreyas\\appdata\\roaming\\python\\python38\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\shreyas\\appdata\\roaming\\python\\python38\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\shreyas\\appdata\\roaming\\python\\python38\\site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\shreyas\\appdata\\roaming\\python\\python38\\site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\shreyas\\appdata\\roaming\\python\\python38\\site-packages (from pdfminer.six==20231228->pdfplumber) (46.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\shreyas\\appdata\\roaming\\python\\python38\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.13.2 in c:\\users\\shreyas\\appdata\\roaming\\python\\python38\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (4.13.2)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atchdog (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -equests (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install --user pdfplumber pytesseract pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c7a67cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b607e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pdfplumberNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 0.11.5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atchdog (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -equests (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary: Plumb a PDF for detailed information about each char, rectangle, and line.\n",
      "Home-page: https://github.com/jsvine/pdfplumber\n",
      "Author: Jeremy Singer-Vine\n",
      "Author-email: jsvine@gmail.com\n",
      "License: \n",
      "Location: c:\\users\\shreyas\\appdata\\roaming\\python\\python38\\site-packages\n",
      "Requires: pdfminer.six, Pillow, pypdfium2\n",
      "Required-by: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%pip show pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "812aa5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shreyas Shetty\n",
      "220 Wallace Street, G5 8AH Glasgow, UK\n",
      "+44 7741857511| shreyasshetty648@gmail.com | linkedin.com/in/shreyas-g-shetty | https://github.com/sshettyongit\n",
      "Having recently graduated in MSc Data Analytics from Strathclyde University along with 2 years of work experience as a Data\n",
      "Analyst at Capgemini and customer facing roles, Seeking tech-focused, customer-facing roles in data analytics. I have the active\n",
      "right to work in the UK and am open to fixed-term contracts.\n",
      "EXPERIENCE\n",
      "PAST DUE CREDIT SOLUTIONS LTD | GLASGOW, UK\n",
      "Mar 25 –\n",
      "Present Financial Customer Representative\n",
      " Analysed 100+ customer financial data daily to evaluate affordability and negotiate payment plans using Excel\n",
      "Macros and Xlookup Functions\n",
      " Effectively resolved complex financial customer issues and acquiring payments adhering to FCA guidelines.\n",
      " Collaborated with 8+ stakeholders (HMRC, DVLA) maintaining 85% QA while reducing customer detriment\n",
      " Mitigated and helped customers who were financially vulnerable by directed to specific support groups.\n",
      "CAPGEMINI TECHNOLOGY SERVICES LTD\n",
      "Dec 22 –\n",
      "Aug 23 Associate Data Analyst\n",
      " Automated recurring Excel-based reports using Power Query and SQL, reducing manual effort by 40%.\n",
      " Developed and maintained interactive Power BI dashboards used by 70+ clients to track performance\n",
      "metrics, identify trends, and support cost optimization strategies leading to gross profit of £ 21.52 B\n",
      " Designed and executed monthly audit SQL scripts, reindexing large fact tables to optimize query\n",
      "performance, validating partitioned revenue and volume metrics across the product portfolio, using\n",
      "Azure Databricks and Azure Synapse.\n",
      "CAPGEMINI TECHNOLOGY SERVICES LTD\n",
      "June 21 –\n",
      "Dec 22 Data Analyst\n",
      " Achieved 100% data recovery for 5000+ daily global file transformations using ADF, ensuring 99.5% system\n",
      "uptime and seamless operations for APAC/EMEA/LATAM financial reporting and analytics.\n",
      " Utilised Azure SQL queries to perform quarterly audits on Azure Cosmos DB vs Cube data discrepancies for\n",
      "300+ client users, ensuring GDPR compliance and data integrity.\n",
      " Worked on optimizing PowerBI dashboards and create measures to deliver insights to the development team\n",
      "to ensure the feature rollouts have been successfully implemented.\n",
      "SKILLS\n",
      " Data Tools: SQL, Power BI, Python, R, Git (Version Control), Excel, Jupyter Notebook\n",
      " Cloud Platforms: Azure Data Factory (ADF), Azure Data Lake, Databricks, Machine Learning, Statistical\n",
      "Analysis, Data Wrangling, Data Visualization\n",
      " Core Strengths: Analytical Thinking, Collaborative, Attention to Detail, Data Storytelling, Requirements\n",
      "gathering, stakeholder engagement, documentation, change management.\n",
      "EDUCATION\n",
      "Sept23’ - MSc. Data Analytics\n",
      "Sept 24’ UNIVERSITY OF STRATHCLYDE | GLASGOW, UK | GRADE - MERIT\n",
      "May 17’- Bachelor of Engineering. Information Technology\n",
      "May 21’ UNIVERSITY OF MUMBAI | INDIA | GRADE - 8.55/10\n",
      "REFERENCES AVAILABLE ON REQUEST\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    return text\n",
    "\n",
    "resume_text  = extract_text_from_pdf(\"Shreyas_resume_Tesco.pdf\")\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "77cc96da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shreyas shetty 220 wallace street, g5 8ah glasgow, uk +44 7741857511| shreyasshetty648@gmail.com | linkedin.com/in/shreyas-g-shetty | https://github.com/sshettyongit having recently graduated in msc data analytics from strathclyde university along with 2 years of work experience as a data analyst at capgemini and customer facing roles, seeking tech-focused, customer-facing roles in data analytics. i have the active right to work in the uk and am open to fixed-term contracts. experience past due credit solutions ltd | glasgow, uk mar 25 – present financial customer representative  analysed 100+ customer financial data daily to evaluate affordability and negotiate payment plans using excel macros and xlookup functions  effectively resolved complex financial customer issues and acquiring payments adhering to fca guidelines.  collaborated with 8+ stakeholders (hmrc, dvla) maintaining 85% qa while reducing customer detriment  mitigated and helped customers who were financially vulnerable by directed to specific support groups. capgemini technology services ltd dec 22 – aug 23 associate data analyst  automated recurring excel-based reports using power query and sql, reducing manual effort by 40%.  developed and maintained interactive power bi dashboards used by 70+ clients to track performance metrics, identify trends, and support cost optimization strategies leading to gross profit of £ 21.52 b  designed and executed monthly audit sql scripts, reindexing large fact tables to optimize query performance, validating partitioned revenue and volume metrics across the product portfolio, using azure databricks and azure synapse. capgemini technology services ltd june 21 – dec 22 data analyst  achieved 100% data recovery for 5000+ daily global file transformations using adf, ensuring 99.5% system uptime and seamless operations for apac/emea/latam financial reporting and analytics.  utilised azure sql queries to perform quarterly audits on azure cosmos db vs cube data discrepancies for 300+ client users, ensuring gdpr compliance and data integrity.  worked on optimizing powerbi dashboards and create measures to deliver insights to the development team to ensure the feature rollouts have been successfully implemented. skills  data tools: sql, power bi, python, r, git (version control), excel, jupyter notebook  cloud platforms: azure data factory (adf), azure data lake, databricks, machine learning, statistical analysis, data wrangling, data visualization  core strengths: analytical thinking, collaborative, attention to detail, data storytelling, requirements gathering, stakeholder engagement, documentation, change management. education sept23’ - msc. data analytics sept 24’ university of strathclyde | glasgow, uk | grade - merit may 17’- bachelor of engineering. information technology may 21’ university of mumbai | india | grade - 8.55/10 references available on request\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "cleaned_text = clean_text(resume_text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95ddbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Detect if the resume is image-based and extract text using OCR\n",
    "# def extract_text_from_image_pdf(pdf_path):\n",
    "#     images = convert_from_path(pdf_path)\n",
    "#     text = \"\"\n",
    "#     for image in images:\n",
    "#         text += pytesseract.image_to_string(image)\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "434fc551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the email\n",
    "email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
    "emails = re.findall(email_pattern, cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "375db77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the phone number\n",
    "phone_pattern = r\"\\+?\\d[\\d -]{8,}\\d\"    \n",
    "phone = re.findall(phone_pattern, cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52e0782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: ['shreyasshetty648@gmail.com']\n",
      "Phone ['+44 7741857511']\n"
     ]
    }
   ],
   "source": [
    "print(\"Email:\", emails)\n",
    "print(\"Phone\", phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "58b1c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sections Found: ['Education', 'Skills', 'Experience']\n"
     ]
    }
   ],
   "source": [
    "# Check for common sections\n",
    "sections = [\"Education\", \"Skills\", \"Experience\", \"Projects\", \"Certifications\", \"Extracurricular Activities\"]\n",
    "# Create an empty list to store found sections\n",
    "found_sections = []\n",
    "# found_sections = {sections: sections.lower() in resume_text for sections in sections}\n",
    "# print(\"Sections found:\", found_sections)\n",
    "\n",
    "# Iterate through each section and check if it's in the resume text\n",
    "for section in sections:\n",
    "    # Check case-insensitively if the lowercase version of the section is in the lowercase resume text\n",
    "    if section.lower() in cleaned_text.lower():\n",
    "        found_sections.append(section)\n",
    "\n",
    "print(\"Sections Found:\", found_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fd452295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'email': True, 'phone': True, 'has_experience': True, 'has_education': True, 'has_skills': True, 'has_projects': False, 'has_certifications': False, 'has_extracurricular_activities': False}\n"
     ]
    }
   ],
   "source": [
    "feaures = {\n",
    "    \"email\" : len(emails)>0,\n",
    "    \"phone\" : len(phone)>0,\n",
    "    \"has_experience\" : \"experience\" in cleaned_text,\n",
    "    \"has_education\": \"education\" in cleaned_text,\n",
    "    \"has_skills\": \"skills\" in cleaned_text,\n",
    "    \"has_projects\": \"projects\" in cleaned_text,\n",
    "    \"has_certifications\": \"certifications\" in cleaned_text,\n",
    "    \"has_extracurricular_activities\": \"extracurricular activities\" in cleaned_text\n",
    "}\n",
    "print(feaures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8667ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on job description my skills should match and also \n",
    "# try to show graph about the possibitlity for me getting th job and \n",
    "# also use either bert or heuristic by deciding which is best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3743006",
   "metadata": {},
   "source": [
    "\"Weights for the features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b8a4abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_weights = {\n",
    "#     \"email\": 15,\n",
    "#     \"phone\": 15,\n",
    "#     \"has_experience\": 25,\n",
    "#     \"has_education\": 20,\n",
    "#     \"has_skills\": 10,\n",
    "#     \"has_projects\": 10,\n",
    "#     \"has_certifications\": 5,\n",
    "#     \"has_extracurricular_activities\": 5\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb91bd",
   "metadata": {},
   "source": [
    "Computing the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2fdcdd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_score(feaures, feature_weights):\n",
    "#     score = 0\n",
    "#     for feature, weight in feature_weights.items():\n",
    "#         if feaures.get(feature):\n",
    "#             score += weight\n",
    "    \n",
    "#     # Total Score\n",
    "#     if score >100:\n",
    "#         score = 100\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "12f65dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(compute_score(feaures, feature_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70e14f1",
   "metadata": {},
   "source": [
    "Computing a deeper level score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c94c286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afde5bdb",
   "metadata": {},
   "source": [
    "EXTRACTING PRESENT AND MISSING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4aacb1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features missing in resume:\n",
      "['has_projects', 'has_certifications', 'has_extracurricular_activities']\n",
      "Features present in resume:\n",
      "['email', 'phone', 'has_experience', 'has_education', 'has_skills']\n"
     ]
    }
   ],
   "source": [
    "false_features = []\n",
    "true_features = []\n",
    "\n",
    "for key, value in feaures.items():\n",
    "    if not value:                                      # if value is False\n",
    "        false_features.append(key)\n",
    "    else:\n",
    "        true_features.append(key)\n",
    "print(\"Features missing in resume:\")\n",
    "print(false_features)\n",
    "print(\"Features present in resume:\")\n",
    "print(true_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31dbde",
   "metadata": {},
   "source": [
    "WEIGHTS FOR FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c80ef771",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights = {\n",
    "    \"email\": 10,\n",
    "    \"phone\": 10,\n",
    "    \"has_experience\": 10,\n",
    "    \"has_education\": 5,\n",
    "    \"has_skills\": 10,\n",
    "    \"has_projects\": 5,\n",
    "    # \"has_certifications\": 5,\n",
    "    # \"has_extracurricular_activities\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8a6f5",
   "metadata": {},
   "source": [
    "CALCULATING THE SECTION SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "519cb91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Section Score is:  45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_score = 50 # Start with base score as 50\n",
    "\n",
    "for feature in false_features:\n",
    "    total_score -= feature_weights.get(feature, 0)  #Subtract its weight (default to 0 if not found) if feature is missing\n",
    "        \n",
    "print(\"Feature Section Score is: \", total_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea510b3",
   "metadata": {},
   "source": [
    "FORMATING SCORE FOR RESUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_format(cleaned_text):\n",
    "    issues = []\n",
    "\n",
    "    # 1. Section headings\n",
    "    headings = [\"experience\", \"education\", \"skills\", \"projects\", \"certifications\"]\n",
    "    for heading in headings:\n",
    "        if heading not in recleaned_text.lower():\n",
    "            issues.append(f\"Missing section: {heading.title()}\")\n",
    "\n",
    "    # 2. Bullet points\n",
    "    if \"-\" not in cleaned_text and \"*\" not in cleaned_text:\n",
    "        issues.append(\"No bullet points detected\")\n",
    "\n",
    "    # 3. Long paragraphs check\n",
    "    lines = cleaned_text.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if len(line) > 200:  # arbitrary threshold for long line\n",
    "            issues.append(\"Long paragraph detected; consider breaking into bullet points\")\n",
    "            break\n",
    "    \n",
    "    # 4. Font consistency - Placeholder (requires more complex PDF parsing)\n",
    "    # 5. Contact information placement - Placeholder (requires layout analysis)\n",
    "    # 6. No tables/images - Placeholder (requires layout analysis)\n",
    "    # 7. Single-column layout - Placeholder (requires layout analysis)\n",
    "    return issues\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
